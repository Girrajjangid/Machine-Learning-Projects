{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'F:/Books/Machine Learning/DataSets/Titanic'\n",
    "raw_data = pd.read_csv('all_data.csv')\n",
    "train_label = pd.read_csv('labels.csv')\n",
    "sub_data = pd.read_csv(path + '/gender_submission.csv')\n",
    "\n",
    "# One Hot Encoding\n",
    "raw_data = pd.concat([raw_data , pd.get_dummies(raw_data.Sex,drop_first=True,prefix='Sex'),\n",
    "pd.get_dummies(raw_data.Pclass,drop_first=True,prefix='Pclass'),\n",
    "pd.get_dummies(raw_data.Embarked,drop_first=True,prefix='Embarked')],axis=1)\n",
    "raw_data.drop(['Pclass','Embarked','Sex'],axis=1,inplace=True)\n",
    "raw_data.head()\n",
    "\n",
    "# Seperating data\n",
    "train_data = raw_data.iloc[:891]\n",
    "test_data = raw_data.iloc[891:]\n",
    "\n",
    "## Normalize\n",
    "sc_age = StandardScaler()\n",
    "train_data.Age = sc_age.fit_transform(train_data.Age.values.reshape(-1,1))\n",
    "\n",
    "sc_fare = StandardScaler()\n",
    "train_data.Fare = sc_fare.fit_transform(train_data.Fare.values.reshape(-1,1))\n",
    "\n",
    "# Remove outliers\n",
    "drop_obser = []\n",
    "drop_obser.extend(train_data.SibSp[train_data.SibSp > 5].index.tolist())\n",
    "drop_obser.extend(train_data.Parch[train_data.Parch > 4].index.tolist())\n",
    "train_data.drop(set(drop_obser),inplace=True)\n",
    "train_label.drop(set(drop_obser),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost              import XGBClassifier\n",
    "from sklearn.svm          import SVC\n",
    "from sklearn.ensemble     import RandomForestClassifier\n",
    "from sklearn.ensemble     import AdaBoostClassifier\n",
    "from sklearn.ensemble     import ExtraTreesClassifier \n",
    "from sklearn.ensemble     import GradientBoostingClassifier\n",
    "from sklearn.neighbors    import KNeighborsClassifier\n",
    "from sklearn.metrics      import r2_score, accuracy_score, mean_squared_error\n",
    "from sklearn.pipeline     import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_data,\n",
    "                                                    train_label,\n",
    "                                                   test_size=.30,\n",
    "                                                   random_state= 42,\n",
    "                                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = []\n",
    "n_estimators = 200\n",
    "seed = 42\n",
    "pipelines.append( ( 'SVC' , Pipeline( [('SVC',SVC()) ]) ) ) \n",
    "\n",
    "pipelines.append( ( 'KNN' , Pipeline( [('KNN',KNeighborsClassifier()) ]) ) )\n",
    "\n",
    "pipelines.append( ( 'RF'  , Pipeline( [('RF', RandomForestClassifier(random_state=seed, n_estimators=n_estimators)) ]) ) )\n",
    "\n",
    "pipelines.append( ( 'Ada' , Pipeline( [('Ada',AdaBoostClassifier(random_state=seed    , n_estimators=n_estimators)) ]) ) )\n",
    "\n",
    "pipelines.append( ( 'ET'  , Pipeline( [('ET', ExtraTreesClassifier(random_state=seed  , n_estimators=n_estimators)) ]) ) )\n",
    "\n",
    "pipelines.append( ( 'GB'  , Pipeline( [('GB', GradientBoostingClassifier(random_state=seed)) ]) ) )\n",
    "\n",
    "pipelines.append( ( 'XGB'  , Pipeline( [('XGB', XGBClassifier(random_state=seed)) ]) ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results, names  = [], []\n",
    "for name, model in pipelines:\n",
    "    cv_results = cross_val_score(model, x_train, y_train, cv = 5 ) \n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    \n",
    "fig = plt.figure(figsize=(12,8))    \n",
    "fig.suptitle(\"Algorithms comparison\")\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV1</th>\n",
       "      <th>CV2</th>\n",
       "      <th>CV3</th>\n",
       "      <th>CV4</th>\n",
       "      <th>CV5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>SVC</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.766129</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>0.778689</td>\n",
       "      <td>0.803279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KNN</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.766129</td>\n",
       "      <td>0.762295</td>\n",
       "      <td>0.811475</td>\n",
       "      <td>0.803279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RF</td>\n",
       "      <td>0.830645</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.762295</td>\n",
       "      <td>0.795082</td>\n",
       "      <td>0.770492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ada</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.798387</td>\n",
       "      <td>0.795082</td>\n",
       "      <td>0.795082</td>\n",
       "      <td>0.795082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ET</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>0.770492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>GB</td>\n",
       "      <td>0.862903</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.811475</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>0.786885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGB</td>\n",
       "      <td>0.879032</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.811475</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>0.811475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CV1       CV2       CV3       CV4       CV5\n",
       "SVC  0.903226  0.766129  0.786885  0.778689  0.803279\n",
       "KNN  0.790323  0.766129  0.762295  0.811475  0.803279\n",
       "RF   0.830645  0.774194  0.762295  0.795082  0.770492\n",
       "Ada  0.838710  0.798387  0.795082  0.795082  0.795082\n",
       "ET   0.741935  0.758065  0.737705  0.770492  0.770492\n",
       "GB   0.862903  0.790323  0.811475  0.786885  0.786885\n",
       "XGB  0.879032  0.774194  0.811475  0.786885  0.811475"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = pd.DataFrame(results,index=names,columns=['CV1','CV2','CV3','CV4','CV5'])\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC Hypertuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8371212121212122"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(x_train,y_train)\n",
    "svc.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:    3.0s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   15.3s remaining:    0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.789902 using {'kernel': 'rbf', 'gamma': 0.01, 'C': 1}\n",
      "0.8068181818181818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   30.0s finished\n",
      "C:\\Users\\GirrajJangid\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'grid_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-26655d2148eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# print classification report\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'grid_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "  # defining parameter range \n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001,5,10], \n",
    "              'kernel': ['linear', 'rbf']}\n",
    "svc = SVC()\n",
    "grid_ = RandomizedSearchCV ( estimator=svc , param_distributions=param_grid,cv = 5,verbose = 10,n_jobs=-1)\n",
    "grid_model = grid_.fit(x_train,y_train) \n",
    "  \n",
    "print(\"Best: %f using %s\" % (grid_model.best_score_, grid_model.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8068181818181818"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {'kernel': 'rbf', 'gamma': 0.01, 'C': 1}\n",
    "svc = SVC(**param)\n",
    "svc.fit(x_train,y_train)\n",
    "svc.score(x_test,y_test)\n",
    "\n",
    "# Dont getting a good pridiction over hypertuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 10 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:   14.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.806189 using {'subsample': 0.6, 'reg_lambda': 1, 'reg_alpha': 0, 'n_estimators': 500, 'min_child_weight': 3, 'max_depth': 7, 'learning_rate': 0.01, 'gamma': 1.5, 'colsample_bytree': 0.8}\n",
      "0.8409090909090909\n"
     ]
    }
   ],
   "source": [
    "params = {'learning_rate':[0.1,0.08,0.05,0.01,0.001],\n",
    "         'gamma':[0.01,0.1,0.3,0.5,1,1.5,2],\n",
    "         'max_depth':[2,4,7,10],\n",
    "         'colsample_bytree':[0.3,0.6,0.8,1],\n",
    "         \"subsample\": [0.2, 0.4, 0.5, 0.6, 0.7],\n",
    "         \"reg_alpha\": [0, 0.5, 1],\n",
    "         \"reg_lambda\": [1, 1.5, 2, 3, 4.5],\n",
    "         \"min_child_weight\": [1, 3, 5, 7],\n",
    "         \"n_estimators\": [100, 250, 500, 1000]}\n",
    "\n",
    "xgb_clf = XGBClassifier()\n",
    "\n",
    "xgb_rscv = RandomizedSearchCV(xgb_clf, param_distributions = params,\n",
    "                             cv = 7, verbose = 3, random_state = 40, n_jobs=-1)\n",
    "\n",
    "model_xgb = xgb_rscv.fit(x_train,y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (model_xgb.best_score_, model_xgb.best_params_))\n",
    "\n",
    "print(model_xgb.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   16.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.817590 using {'subsample': 0.55, 'reg_lambda': 1, 'reg_alpha': 0, 'n_estimators': 520, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.03, 'gamma': 1.2, 'colsample_bytree': 0.9}\n",
      "0.8409090909090909\n"
     ]
    }
   ],
   "source": [
    "best_params = {'subsample': [0.6,0.65,0.55], \n",
    "               'reg_lambda': [1,1.2,0.8] ,\n",
    "               'reg_alpha': [0,0.1,0.09] ,\n",
    "               'n_estimators': [500,450,480,520], \n",
    "               'min_child_weight': [1,2,3], \n",
    "               'max_depth': [7,5,6] ,\n",
    "               'learning_rate': [0.01,0.02,0.03] ,\n",
    "               'gamma': [1.5,1.2,1.7], \n",
    "               'colsample_bytree': [0.8,0.9,0.85]}\n",
    "\n",
    "xgb_rscv = RandomizedSearchCV(xgb_clf, param_distributions = best_params,\n",
    "                             cv = 10, verbose = 3, random_state = 40, n_jobs=-1)\n",
    "\n",
    "model_xgb = xgb_rscv.fit(x_train,y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (model_xgb.best_score_, model_xgb.best_params_))\n",
    "\n",
    "print(model_xgb.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.9, gamma=1.2,\n",
       "              learning_rate=0.03, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=3, missing=None, n_estimators=520, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=0.55, verbosity=1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_1 = {'subsample': 0.6, \n",
    "                 'reg_lambda': 1,\n",
    "                 'reg_alpha': 0, \n",
    "                 'n_estimators': 500, \n",
    "                 'min_child_weight': 3, \n",
    "                 'max_depth': 7,\n",
    "                 'learning_rate': 0.01, \n",
    "                 'gamma': 1.5, \n",
    "                 'colsample_bytree': 0.8}\n",
    "\n",
    "best_params_2 ={ 'subsample': 0.55, \n",
    "                'reg_lambda': 1, \n",
    "                'reg_alpha': 0, \n",
    "                'n_estimators': 520,\n",
    "                'min_child_weight': 3,\n",
    "                'max_depth': 6,\n",
    "                'learning_rate': 0.03,\n",
    "                'gamma': 1.2,\n",
    "                'colsample_bytree': 0.9}\n",
    "\n",
    "xgb_1 = XGBClassifier(**best_params_1)\n",
    "xgb_1.fit(x_train,y_train)\n",
    "\n",
    "xgb_2 = XGBClassifier(**best_params_2)\n",
    "xgb_2.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.803030303030303"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adcl = AdaBoostClassifier()\n",
    "adcl.fit(x_train,y_train)\n",
    "adcl.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:    6.9s remaining:    1.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.804560 using {'n_estimators': 50, 'learning_rate': 0.5}\n",
      "0.7992424242424242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:    7.1s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    7.1s finished\n",
      "C:\\Users\\GirrajJangid\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "param = { 'n_estimators': [50,100,200,500,1000], \n",
    "         'learning_rate': [1.0,0.01,0.1,0.5,0.05]  }\n",
    "\n",
    "adcl = AdaBoostClassifier()\n",
    "adb_rscv = RandomizedSearchCV(adcl, param_distributions = param,\n",
    "                             cv = 5, verbose = 10, random_state = 40, n_jobs=-1)\n",
    "\n",
    "model_adb = adb_rscv.fit(x_train,y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (model_adb.best_score_, model_adb.best_params_))\n",
    "\n",
    "print(model_adb.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesnt provide good solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "svc = SVC()\n",
    "svc.fit(x_train,y_train)\n",
    "y_pred_svc = svc.predict(x_test)\n",
    "df = pd.concat([df , pd.DataFrame(y_pred_svc,columns=['SVC'])],axis=1)\n",
    "\n",
    "adb = AdaBoostClassifier()\n",
    "adb.fit(x_train,y_train)\n",
    "y_pred_adb = adb.predict(x_test)\n",
    "df = pd.concat([df , pd.DataFrame(y_pred_adb,columns=['ADB'])],axis=1)\n",
    "\n",
    "best_params_1 = {'subsample': 0.6, \n",
    "                 'reg_lambda': 1,\n",
    "                 'reg_alpha': 0, \n",
    "                 'n_estimators': 500, \n",
    "                 'min_child_weight': 3, \n",
    "                 'max_depth': 7,\n",
    "                 'learning_rate': 0.01, \n",
    "                 'gamma': 1.5, \n",
    "                 'colsample_bytree': 0.8}\n",
    "xgb_1 = XGBClassifier(**best_params_1)\n",
    "xgb_1.fit(x_train,y_train)\n",
    "y_pred_xgb1 = xgb_1.predict(x_test)\n",
    "df = pd.concat([df , pd.DataFrame(y_pred_xgb1,columns=['XGB_1'])],axis=1)\n",
    "\n",
    "\n",
    "best_params_2 ={ 'subsample': 0.55, \n",
    "                'reg_lambda': 1, \n",
    "                'reg_alpha': 0, \n",
    "                'n_estimators': 520,\n",
    "                'min_child_weight': 3,\n",
    "                'max_depth': 6,\n",
    "                'learning_rate': 0.03,\n",
    "                'gamma': 1.2,\n",
    "                'colsample_bytree': 0.9}\n",
    "\n",
    "\n",
    "xgb_2 = XGBClassifier(**best_params_2)\n",
    "xgb_2.fit(x_train,y_train)\n",
    "y_pred_xgb2 = xgb_2.predict(x_test)\n",
    "df = pd.concat([df , pd.DataFrame(y_pred_xgb2,columns=['XGB_2'])],axis=1)\n",
    "\n",
    "gdb = GradientBoostingClassifier()\n",
    "gdb.fit(x_train,y_train)\n",
    "y_pred_gdb = gdb.predict(x_test)\n",
    "df = pd.concat([df , pd.DataFrame(y_pred_adb,columns=['GRB'])],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88       165\n",
      "           1       0.81      0.76      0.78        99\n",
      "\n",
      "    accuracy                           0.84       264\n",
      "   macro avg       0.83      0.82      0.83       264\n",
      "weighted avg       0.84      0.84      0.84       264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_2.predict(x_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86       165\n",
      "           1       0.76      0.79      0.77        99\n",
      "\n",
      "    accuracy                           0.83       264\n",
      "   macro avg       0.81      0.82      0.82       264\n",
      "weighted avg       0.83      0.83      0.83       264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,df.mode(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8409090909090909"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred_xgb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_2 ={ 'subsample': 0.55, \n",
    "                'reg_lambda': 1, \n",
    "                'reg_alpha': 0, \n",
    "                'n_estimators': 520,\n",
    "                'min_child_weight': 3,\n",
    "                'max_depth': 6,\n",
    "                'learning_rate': 0.03,\n",
    "                'gamma': 1.2,\n",
    "                'colsample_bytree': 0.9}\n",
    "\n",
    "\n",
    "xgb_2 = XGBClassifier(**best_params_2)\n",
    "xgb_2.fit(train_data,train_label)\n",
    "y_pred_xgb2 = xgb_2.predict(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data.Survived = y_pred_xgb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data.Survived = y_pred_xgb2\n",
    "sub_data.to_csv('submission2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>413</td>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>414</td>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>415</td>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>417</td>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         1\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         0\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('submission2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

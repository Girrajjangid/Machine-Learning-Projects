{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "su00atkqqzjZ",
    "outputId": "ada55cad-f86a-4919-bc39-a746d0b0b501"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 87.9MB 359kB/s \n",
      "\u001b[K     |████████████████████████████████| 501kB 43.2MB/s \n",
      "\u001b[K     |████████████████████████████████| 3.1MB 34.2MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q tensorflow==2.0.0-beta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-IF3LjvXqdJi"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import unicodedata\n",
    "import string\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "cUoGvxNddFHh",
    "outputId": "7e1b86b4-0462-4653-fb0c-35b3719f760d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "44g54wKWqdJp",
    "outputId": "112f25af-1c1d-4e1a-9869-e5ee602d5366"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n"
     ]
    }
   ],
   "source": [
    "keras = tf.keras\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "DEed-KleNdUK",
    "outputId": "4a4373cb-9ab9-4fc5-b654-b5bb8b6cbd65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-08-06 15:09:06--  https://www.manythings.org/anki/fra-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 104.24.108.196, 104.24.109.196, 2606:4700:30::6818:6cc4, ...\n",
      "Connecting to www.manythings.org (www.manythings.org)|104.24.108.196|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3476836 (3.3M) [application/zip]\n",
      "Saving to: ‘fra-eng.zip’\n",
      "\n",
      "fra-eng.zip         100%[===================>]   3.32M  2.39MB/s    in 1.4s    \n",
      "\n",
      "2019-08-06 15:09:08 (2.39 MB/s) - ‘fra-eng.zip’ saved [3476836/3476836]\n",
      "\n",
      "Archive:  fra-eng.zip\n",
      "  inflating: _about.txt              \n",
      "  inflating: fra.txt                 \n"
     ]
    }
   ],
   "source": [
    "!wget https://www.manythings.org/anki/fra-eng.zip\n",
    "!unzip  fra-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UHgfCZXVqdJu"
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KSK6zPRUqdJz"
   },
   "outputs": [],
   "source": [
    "class Lang(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2int = {}\n",
    "        self.word2count = {}\n",
    "        self.int2word = {0 : \"SOS\", 1 : \"EOS\"}\n",
    "        self.n_words = 2\n",
    "        \n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2int:\n",
    "            self.word2int[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.int2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "            \n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "    \n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            self.addWord(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8UujikttqdJ7"
   },
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return \"\".join(c for c in unicodedata.normalize(\"NFD\", s) \\\n",
    "                   if unicodedata.category(c) != \"Mn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sb0sLusAqdKA"
   },
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    \n",
    "    s = re.sub(r\"([!.?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z?.!]+\", \" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mbvFe0iqqdKF"
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    with open(\"fra.txt\",'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    pairs = [[normalizeString(pair) for pair in \n",
    "              line.strip().split('\\t')] for line in lines]\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "26fM5LRUqdKJ"
   },
   "outputs": [],
   "source": [
    "pairs = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jnmGqtDOqdKN"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "def sentencetoIndexes(sentence, lang):\n",
    "    indexes = [lang.word2int[word] for word in sentence.split()]\n",
    "    indexes.append(EOS_token)\n",
    "    return indexes\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split()) < MAX_LENGTH and \\\n",
    "len(p[1].split()) < MAX_LENGTH\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "pairs = filterPairs(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GQbB37mcsHb_",
    "outputId": "fad2916c-973b-49e3-9543-ca0dbefa43ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go .', 'va !']"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JlAGPZShqdKT"
   },
   "outputs": [],
   "source": [
    "def build_lang(lang1, lang2, max_length=10):\n",
    "    input_lang = Lang(lang1)\n",
    "    output_lang = Lang(lang2)\n",
    "    input_seq = []\n",
    "    output_seq = []\n",
    "    \n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[1])\n",
    "        output_lang.addSentence(pair[0])\n",
    "    for pair in pairs:\n",
    "        input_seq.append(sentencetoIndexes(pair[1], input_lang))\n",
    "        output_seq.append(sentencetoIndexes(pair[0], output_lang))\n",
    "    return keras.preprocessing.sequence.pad_sequences(input_seq, maxlen=max_length, padding='post',\n",
    "                                                      truncating='post'), \\\n",
    "keras.preprocessing.sequence.pad_sequences(output_seq, padding='post', truncating='post'), input_lang, output_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q9MAxjU-qdKY"
   },
   "outputs": [],
   "source": [
    "input_tensor, output_tensor, input_lang, output_lang = build_lang('fr', 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YZ8Pcm1Ls8Cc",
    "outputId": "2937839a-ccbd-4eba-da49-85f03e91bdbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fr'"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qii6d6iKqdKc"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "BUFFER_SIZE = len(input_tensor)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor, output_tensor)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "41nSXuflqdKh"
   },
   "outputs": [],
   "source": [
    "class Encoder(keras.models.Model):\n",
    "    def __init__(self, vocab_size, num_hidden=256, num_embedding=256, batch_size=16):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_embedding = num_embedding\n",
    "        self.embedding = keras.layers.Embedding(vocab_size, num_embedding)\n",
    "        self.gru = keras.layers.GRU(num_hidden, return_sequences=True,\n",
    "                                    recurrent_initializer='glorot_uniform',\n",
    "                                   return_state=True)\n",
    "        \n",
    "    def call(self, x, hidden):\n",
    "        embedded = self.embedding(x)\n",
    "        rnn_out, hidden = self.gru(embedded, initial_state=hidden)\n",
    "        return rnn_out, hidden\n",
    "    def init_hidden(self):\n",
    "        return tf.zeros(shape=(self.batch_size, self.num_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7qm8zLgoqdKk"
   },
   "outputs": [],
   "source": [
    "inputs, outputs = next(iter(dataset))\n",
    "hidden = tf.zeros((16, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5AHvxMiqdKo"
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(input_lang.n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bCF-S8fBqdKs"
   },
   "outputs": [],
   "source": [
    "e_outputs, e_hidden = encoder(inputs, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "AqGefguVqdKv",
    "outputId": "0b8b976b-6267-40b2-be27-f663781cf1f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=486, shape=(16, 256), dtype=float32, numpy=\n",
       "array([[-0.00396907,  0.01704409,  0.00446016, ...,  0.0267062 ,\n",
       "        -0.01119682,  0.00957247],\n",
       "       [-0.00420967,  0.00417647,  0.00625682, ...,  0.03120756,\n",
       "        -0.01008392, -0.01109486],\n",
       "       [-0.00401135, -0.00325383, -0.00045043, ...,  0.0257953 ,\n",
       "        -0.01152863, -0.02476963],\n",
       "       ...,\n",
       "       [-0.0013465 , -0.00766336, -0.00249992, ...,  0.02202344,\n",
       "        -0.01154935, -0.03394369],\n",
       "       [-0.00038252, -0.00912181, -0.0056711 , ...,  0.01665632,\n",
       "        -0.01284559, -0.03672831],\n",
       "       [-0.00754149,  0.0141846 ,  0.0126119 , ...,  0.02537916,\n",
       "        -0.00813248,  0.01198819]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_bJHJsq1qdK6"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(keras.models.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "    \n",
    "        self.W1 = keras.layers.Dense(units)\n",
    "        self.W2 = keras.layers.Dense(units)\n",
    "        self.V = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, encoder_out, hidden):\n",
    "        #shape of encoder_out : batch_size, seq_length, hidden_dim \n",
    "        #shape of encoder_hidden : batch_size, hidden_dim \n",
    "        \n",
    "        hidden = tf.expand_dims(hidden, axis=1) #out:\n",
    "        \n",
    "        score = self.V(tf.nn.tanh(self.W1(encoder_out) + \\\n",
    "                                  self.W2(hidden))) \n",
    "        \n",
    "        attn_weights = tf.nn.softmax(score, axis=1)\n",
    "        \n",
    "        context =  attn_weights * encoder_out \n",
    "        context = tf.reduce_sum(context, axis=1)\n",
    "        return context, attn_weights\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4gRC60cCqdK-"
   },
   "outputs": [],
   "source": [
    "attn = BahdanauAttention(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OHU6rIRzqdLC"
   },
   "outputs": [],
   "source": [
    "context, attn_weights = attn(e_outputs, e_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "G2XacZYkqdLK",
    "outputId": "2f5997bb-f3bd-4679-e12a-70f2181bfbe6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 10, 1])"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WsLImrCwqdLT"
   },
   "outputs": [],
   "source": [
    "class Decoder(keras.models.Model):\n",
    "    def __init__(self, vocab_size, dec_dim=256, embedding_dim=256):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.attn = BahdanauAttention(dec_dim)\n",
    "        self.embedding = keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = keras.layers.GRU(dec_dim, recurrent_initializer='glorot_uniform',\n",
    "                                   return_sequences=True, return_state=True)\n",
    "        self.fc = keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x, enc_hidden, enc_out):\n",
    "        x = self.embedding(x)\n",
    "        context, attn_weights = self.attn(enc_out, enc_hidden)\n",
    "        x = tf.concat((tf.expand_dims(context, 1), x), -1)\n",
    "        r_out, hidden = self.gru(x, initial_state=enc_hidden)\n",
    "        out = tf.reshape(r_out,shape=(-1, r_out.shape[2]))\n",
    "        return self.fc(out), hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ItYHAqWJqdLY"
   },
   "outputs": [],
   "source": [
    "decoder = Decoder(output_lang.n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XnhNtfb9qdLe"
   },
   "outputs": [],
   "source": [
    "input_tensor, output_tensor = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G7Y7QsykqdLi"
   },
   "outputs": [],
   "source": [
    "x = np.expand_dims(output_tensor[:,1], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1DE7fnvAqdLp"
   },
   "outputs": [],
   "source": [
    "def loss_fn(real, pred):\n",
    "    criterion = keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
    "                                                           reduction='none')\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    _loss = criterion(real, pred)\n",
    "    mask = tf.cast(mask, dtype=_loss.dtype)\n",
    "    _loss *= mask\n",
    "    return tf.reduce_mean(_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MMc7zD6WqdLt"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hiAmynEsqdLw"
   },
   "outputs": [],
   "source": [
    "def train_step(input_tensor, target_tensor, enc_hidden):\n",
    "    loss = 0.0\n",
    "    with tf.GradientTape() as tape:\n",
    "    \n",
    "        batch_size = input_tensor.shape[0]\n",
    "        enc_output, enc_hidden = encoder(input_tensor, enc_hidden)\n",
    "\n",
    "        SOS_tensor = np.array([SOS_token])\n",
    "        dec_input = tf.squeeze(tf.expand_dims([SOS_tensor]*batch_size, 1), -1)\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        for tx in range(target_tensor.shape[1]-1):\n",
    "          \n",
    "            dec_out, dec_hidden, _ = decoder(dec_input, dec_hidden,\n",
    "                                            enc_output)\n",
    "            loss += loss_fn(target_tensor[:, tx], dec_out)\n",
    "            dec_input = tf.expand_dims(target_tensor[:, tx], 1)\n",
    "\n",
    "    batch_loss = loss / target_tensor.shape[1]\n",
    "    t_variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, t_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, t_variables))\n",
    "    return batch_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6kj6diJMqdL0",
    "outputId": "97f30803-0152-4e1a-dee9-92d68251ec4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(7.139749, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "hidden = tf.zeros(shape=(16, 256))\n",
    "loss = train_step(input_tensor, output_tensor, hidden)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lk_OG391qdL5"
   },
   "outputs": [],
   "source": [
    "def checkpoint(model, name=None):\n",
    "    if name is not None:\n",
    "        model.save_weights('/content/gdrive/My Drive/{}.h5'.format(name))\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rZEbkwx9qdL-"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "log_every = 50\n",
    "steps_per_epoch = len(pairs) // BATCH_SIZE\n",
    "loss_list = []\n",
    "\n",
    "for e in range(1, EPOCHS):\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    enc_hidden = encoder.init_hidden()\n",
    "    \n",
    "    for idx, (input_tensor, target_tensor) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(input_tensor, target_tensor, hidden)\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        if idx % log_every == 0:\n",
    "            loss_list.append(batch_loss)\n",
    "            print(\"Epochs: {} batch_loss: {:.4f}\".format(e, batch_loss))\n",
    "            checkpoint(encoder, 'encoder')\n",
    "            checkpoint(decoder, 'decoder')\n",
    "            \n",
    "    if e % 2 == 0:\n",
    "        print(\"Epochs: {}/{} total_loss: {:.4f}\".format(\n",
    "        e, EPOCHS, total_loss / steps_per_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JuswAWMYqdME"
   },
   "outputs": [],
   "source": [
    "def translate(sentence, max_length=10):\n",
    "    result = ''\n",
    "    attention_plot = np.zeros((10,10))\n",
    "    sentence = normalizeString(sentence)\n",
    "    sentence = sentencetoIndexes(sentence, input_lang)\n",
    "    sentence = keras.preprocessing.sequence.pad_sequences([sentence],padding='post',\n",
    "                                                      maxlen=max_length, truncating='post')\n",
    "    \n",
    "    encoder_hidden = hidden = [tf.zeros((1, 256))]\n",
    "    \n",
    "    enc_out, enc_hidden = encoder(sentence, encoder_hidden)\n",
    "    \n",
    "    dec_hidden = enc_hidden\n",
    "    SOS_tensor = np.array([SOS_token])\n",
    "    dec_input = tf.squeeze(tf.expand_dims([SOS_tensor], 1), -1)\n",
    "    \n",
    "    for tx in range(max_length):\n",
    "        dec_out, dec_hidden, attn_weights = decoder(dec_input,\n",
    "                                                   dec_hidden, enc_out)\n",
    "        attn_weights = tf.reshape(attn_weights, (-1, ))\n",
    "        attention_plot[tx] = attn_weights.numpy()\n",
    "        pred = tf.argmax(dec_out, axis=1).numpy()\n",
    "        result += output_lang.int2word[pred[0]] + \" \"\n",
    "        if output_lang.int2word[pred[0]] == \"EOS\":\n",
    "            break\n",
    "        dec_input = tf.expand_dims(pred, axis=1)\n",
    "    return result, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "r7mmzYUIqdMI",
    "outputId": "e78bcf6c-9cea-4d8a-880a-27a4acabc95e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i need somebody to help me ? EOS \n"
     ]
    }
   ],
   "source": [
    "sentence = \"j'ai besoin de quelqu'un pour m'aider ?\"\n",
    "pred, attn_weights = translate(sentence)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-s9cnSvUxNIC"
   },
   "outputs": [],
   "source": [
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    sentence = normalizeString(sentence)\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xpf4T5z_3JP4"
   },
   "outputs": [],
   "source": [
    "from matplotlib import ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "id": "5A9xpAf6xsgL",
    "outputId": "fa47f721-b6e9-4a46-84e2-e402738e7bdc"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-87d681c8761a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-96-e2eb4a2889fa>\u001b[0m in \u001b[0;36mplot_attention\u001b[0;34m(attention, sentence, predicted_sentence)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalizeString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'viridis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-7fa98ec041b7>\u001b[0m in \u001b[0;36mnormalizeString\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnormalizeString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0municodeToAscii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"([!.?])\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr\" \\1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"[^a-zA-Z?.!]+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "attn_weights = attn_weights[:len(pred.split(' ')), :len(sentence.split(' '))]\n",
    "plot_attention(attn_weights, sentence.split(), pred.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yROfA7newSua"
   },
   "outputs": [],
   "source": [
    "encoder.load_weights('/content/gdrive/My Drive/encoder.h5')\n",
    "decoder.load_weights('/content/gdrive/My Drive/decoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5vDXB800z9GC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "machine translation tensorflow orig.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

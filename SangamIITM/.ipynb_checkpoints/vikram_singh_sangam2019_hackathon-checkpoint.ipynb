{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from matplotlib import rcParams\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import plot_importance, plot_tree\n",
    "\n",
    "sb.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Sangam_2019_Hackathon_Data.csv')\n",
    "print(data.shape)\n",
    "\n",
    "#Some display Changes\n",
    "pd.set_option('max_columns',50) \n",
    "pd.set_option('max_rows',1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Exploring the Columns of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Using descriptive Statistics to find some insights\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Checking for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Percentage and Sum of Missing values in each Columns\n",
    "missing_data = pd.DataFrame({'total_missing': data.isnull().sum(), 'perc_missing': (data.isnull().sum()/data.shape[0])*100})\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping Unnecsary Columns\n",
    "data.drop(['S.no'], axis=1, inplace=True)\n",
    "\n",
    "#drop all NaN rows\n",
    "data.dropna(inplace=True) \n",
    "\n",
    "# removing irrealavent Values\n",
    "data.drop(data.loc[(data.device_id == '{\"success\":1') | (data.device_id == \"S81\")].index, inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A(i) Rectifying The Timestamp Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#Handleing the timestamps Columns\n",
    "data.svrtime = pd.to_datetime(data.svrtime,infer_datetime_format=True)\n",
    "data.timestamp = pd.to_datetime(data.timestamp, errors='coerce', infer_datetime_format=True) \n",
    "\n",
    "data.loc[list(data[data.timestamp.isnull()].timestamp.index), 'timestamp']  = data[data.timestamp.isnull()].svrtime\n",
    "\n",
    "data['svrtime'] = data['svrtime'].astype('str')\n",
    "data['timestamp'] = data['timestamp'].astype('str')\n",
    "\n",
    "data['timestamp'] = data.svrtime.str.slice(0,10) + data.timestamp.str.slice(10,)\n",
    "\n",
    "data.svrtime = pd.to_datetime(data.svrtime,infer_datetime_format=True)\n",
    "data.timestamp = pd.to_datetime(data.timestamp, infer_datetime_format=True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A(ii) Rectify/Impute the location Data(GPS Cordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing 0 to Nan's\n",
    "data.latitude = data.latitude.replace(to_replace=[0,1], value=np.nan)\n",
    "data.longitude = data.longitude.replace(to_replace=[0,1], value=np.nan)\n",
    "\n",
    "#replacing the S9 values with given Coordinates\n",
    "data.loc[data.device_id == 'S9', 'latitude']  = data[data.device_id == 'S9'].latitude.fillna(value=13.08827)\n",
    "data.loc[data.device_id == 'S9', 'longitude'] = data[data.device_id == 'S9'].longitude.fillna(value=80.181568)\n",
    "\n",
    "#replacing the S4 coordinates with  mode \n",
    "data.loc[data.device_id == 'S4', 'latitude']  = data[data.device_id == 'S4'].latitude.fillna(value=data[data.device_id ==\"S4\"].latitude.mode()[0])\n",
    "data.loc[data.device_id == 'S4', 'longitude'] = data[data.device_id == 'S4'].longitude.fillna(value=data[data.device_id ==\"S4\"].longitude.mode()[0])\n",
    "\n",
    "#replacing the M7 coordinates with  mode \n",
    "data.loc[data.device_id == 'M7', 'latitude']  = data[data.device_id == 'M7'].latitude.fillna(value=data[data.device_id ==\"M7\"].latitude.mode()[0])\n",
    "data.loc[data.device_id == 'M7', 'longitude'] = data[data.device_id == 'M7'].longitude.fillna(value=data[data.device_id ==\"M7\"].longitude.mode()[0])\n",
    "\n",
    "#Using FFill method to remove the remaining incorrectness in DATA\n",
    "#stationary_device = ['S5', 'S3', 'S4', 'S1','S10', 'S8', 'S9', 'S6', 'S7']\n",
    "for s in list(data.device_id.unique()):\n",
    "    data.loc[data.device_id == s, 'latitude']  = data[data.device_id == s].latitude.fillna(method='ffill')\n",
    "    data.loc[data.device_id == s, 'latitude']  = data[data.device_id == s].latitude.fillna(value=data[data.device_id ==s].latitude.mode()[0])\n",
    "\n",
    "    data.loc[data.device_id == s, 'longitude'] = data[data.device_id == s].longitude.fillna(method='ffill')\n",
    "    data.loc[data.device_id == s, 'longitude'] = data[data.device_id == s].longitude.fillna(value=data[data.device_id ==s].longitude.mode()[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  B.   Finding Outliers and imputing them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Finding Outliers and Imputing  them. [\"Humidity\", 'Temperature', 'heat_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "\n",
    "plt.subplot(3,2, 1)\n",
    "plt.plot(data.humidity, color='red')\n",
    "plt.title(\"Humidity\")\n",
    "\n",
    "plt.subplot(3,2, 2)\n",
    "plt.plot(data.temperature, color='blue')\n",
    "plt.title(\"Temprature\")\n",
    "\n",
    "plt.subplot(3,2, 3)\n",
    "plt.plot(data.heat_index)\n",
    "plt.title(\"Heat Index\", color='black')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handeling outliers in these columns dataframe\n",
    "data.loc[data.humidity > 100, 'humidity'] = data.humidity.median()\n",
    "data.loc[data.temperature > 100 , 'temperature'] = data.temperature.median()\n",
    "data.loc[data.heat_index < 0 , 'heat_index'] = data.heat_index.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing with Nan\n",
    "data.humidity = data.humidity.replace(to_replace=[0,1], value=np.nan)\n",
    "data.temperature = data.temperature.replace(to_replace=[0,1], value=np.nan)\n",
    "data.heat_index = data.heat_index.replace(to_replace=[0,1], value=np.nan)\n",
    "\n",
    "\n",
    "# Removing Outliers from Stationary devices from Columns ['humidity', 'temperature', 'heat_index']\n",
    "st_device = ['S5', 'S3', 'S4', 'S1','S10', 'S8', 'S9', 'S6', 'S7', 'M7', \"M1\", 'M2', 'M3', 'M4', 'M6']\n",
    "for s in st_device:\n",
    "    s_data = data[data.device_id == s]\n",
    "    mean_hth = s_data.mean().tolist()[2:5]\n",
    "    \n",
    "    data.loc[data.device_id == s, 'humidity']  = data[data.device_id == s].humidity.fillna(method='ffill')\n",
    "    data.loc[data.device_id == s, 'humidity']  = data[data.device_id == s].humidity.fillna(value=mean_hth[0])\n",
    "    \n",
    "    data.loc[data.device_id == s, 'temperature']  = data[data.device_id == s].temperature.fillna(method='ffill')\n",
    "    data.loc[data.device_id == s, 'temperature']  = data[data.device_id == s].temperature.fillna(value=mean_hth[1])\n",
    "    \n",
    "    data.loc[data.device_id == s, 'heat_index']  = data[data.device_id == s].heat_index.fillna(method='ffill')\n",
    "    data.loc[data.device_id == s, 'heat_index']  = data[data.device_id == s].heat_index.fillna(value=mean_hth[2])\n",
    "    \n",
    "    #mean_hth = s_data.mean().tolist()[2:5]\n",
    "    #std_hth  = s_data.std().tolist()[2:5]\n",
    "    \n",
    "    #h_index = s_data.loc[s_data.humidity< mean_hth[0]- 1.5*std_hth[0]].index\n",
    "    #t_index = s_data.loc[(mean_hth[1]+ 5*std_hth[1] <s_data.temperature) | s_data.temperature< mean_hth[1]- 5*std_hth[1]].index\n",
    "    #ht_index = s_data.loc[(mean_hth[2]+ 4*std_hth[2] <s_data.heat_index) | s_data.heat_index< mean_hth[2]- 5*std_hth[2]].index\n",
    "    \n",
    "    #data.loc[h_index, 'humidity'] = mean_hth[0]\n",
    "    #data.loc[t_index, 'temperature'] = mean_hth[1]\n",
    "    #data.loc[ht_index, 'heat_index'] = mean_hth[2]\n",
    "    \n",
    "\n",
    "# Column Shit is only present in M5 Device so i am replacing the humidity and temperature for those and remaining missing values  is filling with  MEAN    \n",
    "s_data = data[data.device_id == 'M5']\n",
    "t_index = s_data[s_data.temperature > 60].index\n",
    "temp = data.loc[t_index, 'temperature']\n",
    "humidity = data.loc[t_index, 'humidity']\n",
    "data.loc[t_index, 'temperature'] = s_data.temperature.mean()\n",
    "data.loc[t_index, 'humidity'] = temp \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Handeling Outliers of Longitude And Latitudes for Stationary Devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the Latitudes and Longitudes with their mode for each devices\n",
    "s_device = ['S5', 'S3', 'S4', 'S1', 'M7','S10', 'S8', 'S9', 'S6', 'S7']\n",
    "for s in s_device:\n",
    "    \n",
    "    lat = data[data.device_id == s].latitude.mean()\n",
    "    log = data[data.device_id == s].longitude.median()\n",
    "\n",
    "    data.loc[data.device_id == s, 'latitude'] = lat\n",
    "    data.loc[data.device_id == s, 'longitude'] = log\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Handeling Outliers of Langitude and Latitude for Moving Devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IN LATITUDE\n",
    "m_device = ['M1', 'M2', 'M3', 'M4', 'M5', 'M6']\n",
    "i=1\n",
    "\n",
    "plt.figure(figsize=(18,16))\n",
    "for m in m_device:\n",
    "    \n",
    "    m_data = data[data.device_id == m]\n",
    "\n",
    "    plt.subplot(6,2, i)\n",
    "    plt.plot(m_data['latitude'], color='green')\n",
    "    plt.title(m)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_device = ['M1', 'M2', 'M3', 'M4', 'M5', \"M6\"]\n",
    "\n",
    "mx_lat = [29.5,29.5,29.5,29.5,14,14]\n",
    "mi_lat = [28.2,28.2,28.2,28.2,12.5,12]\n",
    "\n",
    "i=0\n",
    "\n",
    "for m in m_device:\n",
    "    data.loc[(data.device_id == m) & (mx_lat[i]<data['latitude']), 'latitude'] = np.nan\n",
    "    data.loc[(data.device_id == m) & (data['latitude']<mi_lat[i]), 'latitude'] = np.nan\n",
    "    \n",
    "    data.loc[data.device_id == m, 'latitude']  = data[data.device_id == m].latitude.fillna(method ='ffill')\n",
    "    data.loc[data.device_id == m, 'latitude']  = data[data.device_id == m].latitude.fillna(method ='bfill')\n",
    "    data.loc[data.device_id == m, 'latitude']  = data[data.device_id == m].latitude.fillna(value=data[data.device_id ==m].latitude.mode())\n",
    "    i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IN Longitude\n",
    "m_device = ['M1', 'M2', 'M3', 'M4', 'M5', 'M6']\n",
    "i=1\n",
    "\n",
    "plt.figure(figsize=(18,16))\n",
    "for m in m_device:\n",
    "    \n",
    "    m_data = data[data.device_id == m]\n",
    "\n",
    "    plt.subplot(6,2, i)\n",
    "    plt.plot(m_data['longitude'], color='blue')\n",
    "    plt.title(m)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_device = ['M1', 'M2', 'M3', 'M4', 'M5', \"M6\"]\n",
    "\n",
    "mx_log = [78,78,78,78,81,81]\n",
    "mi_log = [76.5,76.5,76.5,76.5,79,79]\n",
    "\n",
    "i=0\n",
    "\n",
    "for m in m_device:\n",
    "    data.loc[(data.device_id == m) & (mx_log[i]<data['longitude']), 'longitude'] = np.nan\n",
    "    data.loc[(data.device_id == m) & (data['longitude']<mi_log[i]), 'longitude'] = np.nan\n",
    "    \n",
    "    data.loc[data.device_id == m, 'longitude']  = data[data.device_id == m].longitude.fillna(method ='ffill')\n",
    "    data.loc[data.device_id == m, 'longitude']  = data[data.device_id == m].longitude.fillna(method ='bfill')\n",
    "    data.loc[data.device_id == m, 'longitude']  = data[data.device_id == m].longitude.fillna(value=data[data.device_id ==m].longitude.mode())\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Handeling Outliers in UV Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data.uv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Replacing Outliers with mode\n",
    "uv_list = list(data[data.uv>10].device_id.value_counts().keys())\n",
    "data.loc[data.uv > 10, \"uv\"] = np.nan\n",
    "\n",
    "for u in uv_list:\n",
    "    data.loc[data.device_id == u, 'uv']  = data[data.device_id == u].uv.fillna(value=data[data.device_id ==u].uv.mode()[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Handeling Outliers in pm01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_device = ['S5', 'S3', 'S4', 'S1', 'M7','S10', 'S8', 'S9', 'S6', 'S7']\n",
    "i=1\n",
    "plt.figure(figsize=(18,16))\n",
    "\n",
    "for s in s_device:\n",
    "    \n",
    "    s_data = data[data.device_id == s]\n",
    "\n",
    "    plt.subplot(10,2, i)\n",
    "    plt.plot(s_data['pm01'], color='red')\n",
    "    plt.title(s)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_device = ['S5', 'S3', 'S4', 'S1', \"S8\",\"S6\", 'S10', 'S9', \"S7\"]\n",
    "p01_data = [250,250,250,250,150,150,400,200,100]\n",
    "i=0\n",
    "\n",
    "for s in s_device:\n",
    "    data.loc[(data.device_id == s) & (data['pm01']>p01_data[i]), 'pm01'] = np.nan\n",
    "    data.loc[data.device_id == s, 'pm01']  = data[data.device_id == s].pm01.fillna(method ='ffill')\n",
    "    data.loc[data.device_id == s, 'pm01']  = data[data.device_id == s].pm01.fillna(value=data[data.device_id ==s].pm01.mean())\n",
    "    i+=1\n",
    "    \n",
    "#for device M7\n",
    "data.loc[(data.device_id == \"M7\") & (data['pm01']<10), 'pm01'] = np.nan\n",
    "data.loc[data.device_id == \"M7\", 'pm01']  = data[data.device_id == \"M7\"].pm01.fillna(method ='ffill')\n",
    "data.loc[data.device_id == \"M7\", 'pm01']  = data[data.device_id == \"M7\"].pm01.fillna(value=data[data.device_id ==\"M7\"].pm01.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Handeling Outliers in pm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_device = ['S5', 'S3', 'S4', 'S1', 'M7','S10', 'S8', 'S9', 'S6', 'S7']\n",
    "i=1\n",
    "plt.figure(figsize=(18,16))\n",
    "\n",
    "for s in s_device:\n",
    "    \n",
    "    s_data = data[data.device_id == s]\n",
    "\n",
    "    plt.subplot(10,2, i)\n",
    "    plt.plot(s_data['pm25'], color='red')\n",
    "    plt.title(s)\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_device = ['S5', 'S3', 'S4', 'S1', \"S8\",\"S6\", 'S10', 'S9', \"S7\"]\n",
    "pm25_data = [400,350,450,450,250,150,500,400,95]\n",
    "i=0\n",
    "\n",
    "for s in s_device:\n",
    "    data.loc[(data.device_id == s) & (data['pm25']>pm25_data[i]), 'pm25'] = np.nan\n",
    "    data.loc[data.device_id == s, 'pm25']  = data[data.device_id == s].pm25.fillna(method ='ffill')\n",
    "    data.loc[data.device_id == s, 'pm25']  = data[data.device_id == s].pm25.fillna(value=data[data.device_id ==s].pm25.mean())\n",
    "    i+=1\n",
    "    \n",
    "#for device M7\n",
    "data.loc[(data.device_id == \"M7\") & (data['pm25']<20), 'pm25'] = np.nan\n",
    "data.loc[data.device_id == \"M7\", 'pm25']  = data[data.device_id == \"M7\"].pm25.fillna(method ='ffill')\n",
    "data.loc[data.device_id == \"M7\", 'pm25']  = data[data.device_id == \"M7\"].pm25.fillna(value=data[data.device_id ==\"M7\"].pm25.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Handeling Outliers in pm10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_device = ['S5', 'S3', 'S4', 'S1', 'M7','S10', 'S8', 'S9', 'S6', 'S7']\n",
    "i=1\n",
    "plt.figure(figsize=(18,16))\n",
    "\n",
    "for s in s_device:\n",
    "    \n",
    "    s_data = data[data.device_id == s]\n",
    "\n",
    "    plt.subplot(10,2, i)\n",
    "    plt.plot(s_data['pm10'], color='red')\n",
    "    plt.title(s)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_device = ['S5', 'S3', 'S4', 'S1', \"S8\",\"S6\", 'S10', 'S9', \"S7\", \"M7\"]\n",
    "pm10_data = [450,450,450,480,350,250,450,450,190,45]\n",
    "i=0\n",
    "\n",
    "for s in s_device:\n",
    "    data.loc[(data.device_id == s) & (data['pm10']>pm10_data[i]), 'pm10'] = np.nan\n",
    "    data.loc[data.device_id == s, 'pm10']  = data[data.device_id == s].pm10.fillna(method ='ffill')\n",
    "    data.loc[data.device_id == s, 'pm10']  = data[data.device_id == s].pm10.fillna(value=data[data.device_id ==s].pm10.mean())\n",
    "    i+=1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

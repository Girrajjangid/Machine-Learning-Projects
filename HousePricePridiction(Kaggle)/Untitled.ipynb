{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libararies\n",
    "import numpy       as np\n",
    "import pandas      as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn     as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Datasets\n",
    "raw_data = pd.read_csv('F:/Books/Machine Learning/DataSets/house-prices-advanced-regression-technique/train.csv') \n",
    "test_data = pd.read_csv('F:/Books/Machine Learning/DataSets/house-prices-advanced-regression-technique/test.csv')\n",
    "\n",
    "raw_label = raw_data.SalePrice\n",
    "raw_data.drop('SalePrice',axis=1,inplace=True)\n",
    "\n",
    "object_features = raw_data.dtypes[raw_data.dtypes == 'object'].keys()\n",
    "int_features    = raw_data.dtypes[raw_data.dtypes == 'int64'].keys()\n",
    "float_features  = raw_data.dtypes[raw_data.dtypes == 'float64'].keys()\n",
    "\n",
    "drop_obj_feat = ['Street','Alley','Utilities','LandSlope','Condition2','RoofMatl','Heating',\n",
    "                'BsmtCond','PoolQC','MiscFeature','HeatingQC','Functional','GarageQual','GarageCond',\n",
    "                'PavedDrive','MiscFeature','ExterCond','CentralAir','Fence','FireplaceQu','MasVnrType']\n",
    "\n",
    "object_features_2 = object_features.drop(drop_obj_feat)\n",
    "\n",
    "null = raw_data[object_features_2].isnull().sum()\n",
    "null_obj = []\n",
    "for key,value in zip(null.index,null.values):\n",
    "    if value == 0:\n",
    "        continue\n",
    "    else:\n",
    "        null_obj.append(key)\n",
    "        \n",
    "raw_data.loc[:,null_obj] = raw_data.loc[:,null_obj].fillna('not_given')\n",
    "\n",
    "split = round(raw_data.shape[0] * .02)  \n",
    "for i in object_features_2:\n",
    "    count = raw_data[i].value_counts()\n",
    "    raw_data[i][raw_data[i].isin(count[count < split].index)] = 'allmix'\n",
    "\n",
    "# Concatinating One hot feature with remaining\n",
    "raw_data = pd.concat([raw_data,pd.get_dummies(raw_data[object_features_2])],axis=1)\n",
    "raw_data.drop(object_features_2, inplace=True,axis=1) # drop these feature because we hot encode these values\n",
    "raw_data.drop(drop_obj_feat, inplace=True,axis=1) # drop these feature because these are not important \n",
    "\n",
    "int_features = raw_data.select_dtypes(['int64']).columns\n",
    "\n",
    "outliers = []\n",
    "drop_int_feat = []\n",
    "outliers.extend(raw_data.LotArea[raw_data.LotArea > 35000].index.tolist()) \n",
    "outliers.extend(raw_data.OverallQual[raw_data.OverallQual < 2].index.tolist()) \n",
    "outliers.extend(raw_data.OverallCond[raw_data.OverallCond < 2].index.tolist())  \n",
    "outliers.extend(raw_data.BsmtFinSF1[raw_data.BsmtFinSF1 > 2500].index.tolist()) \n",
    "outliers.extend(raw_data.LowQualFinSF[raw_data.LowQualFinSF > 500].index.tolist()) \n",
    "outliers.extend(raw_data.BsmtFullBath[raw_data.BsmtFullBath > 2].index.tolist())\n",
    "outliers.extend(raw_data.FullBath[raw_data.FullBath < 1].index.tolist()) \n",
    "outliers.extend(raw_data.BedroomAbvGr[raw_data.BedroomAbvGr > 6].index.tolist())  \n",
    "outliers.extend(raw_data.KitchenAbvGr[raw_data.KitchenAbvGr > 2].index.tolist()) \n",
    "outliers.extend(raw_data.WoodDeckSF[raw_data.WoodDeckSF > 600].index.tolist()) \n",
    "outliers.extend(raw_data.OpenPorchSF[raw_data.OpenPorchSF > 400].index.tolist()) \n",
    "outliers.extend(raw_data.EnclosedPorch[raw_data.EnclosedPorch > 300].index.tolist()) \n",
    "outliers.extend(raw_data.ScreenPorch[raw_data.ScreenPorch > 350].index.tolist())  \n",
    "outliers.extend(raw_data.MiscVal[raw_data.MiscVal > 2100].index.tolist()) \n",
    "\n",
    "drop_int_feat.append('BsmtHalfBath')\n",
    "drop_int_feat.append('BsmtFinSF2')\n",
    "drop_int_feat.append('3SsnPorch')\n",
    "drop_int_feat.append('PoolArea')\n",
    "\n",
    "\n",
    "# Fill missing values after removing outliers\n",
    "\n",
    "outlier = raw_data.LotFrontage[raw_data.LotFrontage > 200].index.tolist()\n",
    "outliers.extend(outlier)\n",
    "m = raw_data.LotFrontage.drop(outlier).mean()\n",
    "s = raw_data.LotFrontage.drop(outlier).std()\n",
    "randoms = np.random.normal(m , s/1.5 , raw_data.LotFrontage.isna().sum())\n",
    "raw_data.LotFrontage[raw_data.LotFrontage.isna()] = randoms\n",
    "\n",
    "\n",
    "outlier = raw_data.MasVnrArea[raw_data.MasVnrArea > 1100].index.tolist()\n",
    "outliers.extend(outlier)\n",
    "m = raw_data.MasVnrArea.drop(outlier).mean()\n",
    "raw_data.MasVnrArea.fillna(m,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "x = np.random.normal(round(raw_data.GarageYrBlt.mean()),\n",
    "                        round(raw_data.GarageYrBlt.std()/2),\n",
    "                        raw_data.GarageYrBlt.isna().sum())\n",
    "raw_data.GarageYrBlt[raw_data.GarageYrBlt.isna()]  =  list(map(round,x))\n",
    "\n",
    "\n",
    "def outlierDetect(df, no_of_feature_contains = 3):\n",
    "    '''pass pandas\"s dataframe'''\n",
    "    outlier_indices = []\n",
    "    for col in df:\n",
    "        q1 = np.percentile(df[col],25)\n",
    "        q3 = np.percentile(df[col],75)\n",
    "        # IQR\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - 1.5 * iqr\n",
    "        upper = q3 + 1.5 * iqr\n",
    "        outlier_index = df[ (df[col] < lower) | (df[col] > upper)].index.tolist()\n",
    "        outlier_indices.extend(outlier_index)\n",
    "\n",
    "    counted_outliers = Counter(outlier_indices)    \n",
    "    indexs = [k for k,v in counted_outliers.items() if v > no_of_feature_contains] \n",
    "    return indexs\n",
    "\n",
    "\n",
    "outliers.extend(outlierDetect(raw_data[int_features],no_of_feature_contains = 5))\n",
    "\n",
    "# Dropping all outliers \n",
    "raw_data.drop(set(outliers), inplace = True)\n",
    "raw_label.drop(set(outliers),inplace = True)\n",
    "\n",
    "# Droping int features\n",
    "raw_data.drop(drop_int_feat,axis=1,inplace=True)\n",
    "\n",
    "int_features = int_features.append(raw_data.select_dtypes('float64').columns)\n",
    "int_features = int_features.drop(drop_int_feat)\n",
    "int_features = int_features.drop('Id')\n",
    "\n",
    "uint8_features = raw_data.select_dtypes('uint8').columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.shape , raw_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Datasets\n",
    "raw_data = pd.read_csv('F:/Books/Machine Learning/DataSets/house-prices-advanced-regression-technique/train.csv') \n",
    "test_data = pd.read_csv('F:/Books/Machine Learning/DataSets/house-prices-advanced-regression-technique/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract different columns between testdata and traindata\n",
    "set(raw_data.columns).difference(test_data.columns) # this is a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate labels from dataset\n",
    "raw_label = raw_data.SalePrice\n",
    "raw_data.drop('SalePrice',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking shape of datasets\n",
    "print(raw_data.shape)\n",
    "print(test_data.shape)\n",
    "print(raw_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about data\n",
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking total no. of object,int,float type features\n",
    "object_features = raw_data.dtypes[raw_data.dtypes == 'object'].keys()\n",
    "int_features    = raw_data.dtypes[raw_data.dtypes == 'int64'].keys()\n",
    "float_features  = raw_data.dtypes[raw_data.dtypes == 'float64'].keys()\n",
    "\n",
    "#raw_data.select_dtypes(include=[object]).columns \n",
    "\n",
    "print(len(object_features)) # 43\n",
    "print(len(int_features))    # 34\n",
    "print(len(float_features))  #  3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Feature Exploration, Engineering and Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Dealing with Object Data_Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(raw_data[object_features].isnull())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in object_features:\n",
    "    sns.countplot(raw_data[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in object_features:\n",
    "    print(raw_data[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "##### Dropping  Object Feature ######\n",
    "#####################################\n",
    "# Street     :: 99% are same (these values dont provide us information because all values are same)\n",
    "# Alley      :: only 91 values remaining are null. So we can drop this column\n",
    "# Utilities  :: 99.99% are same\n",
    "# LandSlope  :: same values most\n",
    "# Condition2 :: same values most\n",
    "# RoofMatl   :: same values most\n",
    "# Heating    :: same values most\n",
    "# BsmtCond   :: same values most\n",
    "# PoolQC     :: null values most\n",
    "# MiscFeature:: null values most\n",
    "# HeatingQC  :: mostly yes\n",
    "# Functional :: not varies\n",
    "# GarageQual :: not varies ## take it\n",
    "# GarageCond :: same value most\n",
    "# PavedDrive :: null value most\n",
    "# MiscFeature:: mostly are null\n",
    "# ExterCond  :: same value most\n",
    "# CentralAir :: not varies\n",
    "# Fence      :: not varies\n",
    "# MasVnrType :: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_obj_feat = ['Street','Alley','Utilities','LandSlope','Condition2','RoofMatl','Heating',\n",
    "                'BsmtCond','PoolQC','MiscFeature','HeatingQC','Functional','GarageQual','GarageCond',\n",
    "                'PavedDrive','MiscFeature','ExterCond','CentralAir','Fence','FireplaceQu','MasVnrType']\n",
    "\n",
    "object_features_2 = object_features.drop(drop_obj_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Dealing with missing values in Object DataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding all null values columns \n",
    "null = raw_data[object_features_2].isnull().sum()\n",
    "null_obj = []\n",
    "for key,value in zip(null.index,null.values):\n",
    "    if value == 0:\n",
    "        continue\n",
    "    else:\n",
    "        null_obj.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_obj  # these are only features which contains null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in null_obj:\n",
    "    sns.countplot(raw_data[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We cannot replace missing values with mode because not all distribution are same\n",
    "# So, we replace with a Fixed value 'notgiven'\n",
    "raw_data.loc[:,null_obj] = raw_data.loc[:,null_obj].fillna('not_given')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data[object_features_2].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Masking the values of Object DataTypes\n",
    "#### I try to reduce the dimension of dataset (Try to avoid this step because it is possible that those values which are less in train data will be more in test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value which are only 2% of all dataset unique will assign in a new column called allmix\n",
    "split = round(raw_data.shape[0] * .02)  \n",
    "for i in object_features_2:\n",
    "    count = raw_data[i].value_counts()\n",
    "    raw_data[i][raw_data[i].isin(count[count < split].index)] = 'allmix'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in object_features_2:\n",
    "    sns.countplot(raw_data[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in object_features_2:\n",
    "    print(raw_data[i].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(raw_data[object_features_2]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatinating One hot feature with remaining\n",
    "raw_data = pd.concat([raw_data,pd.get_dummies(raw_data[object_features_2])],axis=1)\n",
    "raw_data.drop(object_features_2, inplace=True,axis=1) # drop these feature because we hot encode these values\n",
    "raw_data.drop(drop_obj_feat, inplace=True,axis=1) # drop these feature because these are not important "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Dealing with int,float DataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_features = raw_data.select_dtypes(['int64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_data[int_features].hist(bins='auto',figsize=(15,35),layout=(13,3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Dealing with Missing, Outlier of IntDataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.select_dtypes('int64').info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Int datatype features not contains any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.select_dtypes('int64').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Detect Int datatype outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#raw_data.LotArea[raw_data.LotArea > 35000] # drop these 18 observations\n",
    "#raw_data.OverallQual[raw_data.OverallQual < 2]  # 375 , 533\n",
    "## OverallCond ## seem to be important\n",
    "## OverallQual ## seem to be important\n",
    "## raw_data.OverallCond[raw_data.OverallCond < 2]  # 375\n",
    "## yearbuild       ok\n",
    "## yearremodadd    ok\n",
    "#raw_data.BsmtFinSF1[raw_data.BsmtFinSF1 > 2500]   # 1298\n",
    "#raw_data.BsmtFinSF2.value_counts() DROP\n",
    "## BsmtfinUnfSF    ok\n",
    "#raw_data.TotalBsmtSF[raw_data.TotalBsmtSF > 3500]  # 1298\n",
    "#raw_data['1stFlrSF'][raw_data['1stFlrSF'] > 3500]  # 1298\n",
    "# 2ndflrsf         ok\n",
    "#raw_data.LowQualFinSF[raw_data.LowQualFinSF > 500]  # 88,170,185,635,1009\n",
    "#raw_data.GrLivArea[raw_data.GrLivArea > 5000]       # 1298\n",
    "#raw_data.BsmtFullBath[raw_data.BsmtFullBath > 2]  # 738\n",
    "#BsmthalfBath   drop\n",
    "#raw_data.FullBath[raw_data.FullBath < 1] # 9 observations\n",
    "# Halfbath      ok\n",
    "#raw_data.BedroomAbvGr[raw_data.BedroomAbvGr > 6] # 635 \n",
    "#raw_data.KitchenAbvGr[raw_data.KitchenAbvGr > 2] # 48, 809\n",
    "# fireplace     ok\n",
    "# garage cars   ok\n",
    "# garage ares   ok\n",
    "#raw_data.WoodDeckSF[raw_data.WoodDeckSF > 600] # 6 observations\n",
    "#raw_data.OpenPorchSF[raw_data.OpenPorchSF > 400] # 5 observations\n",
    "#raw_data.EnclosedPorch[raw_data.EnclosedPorch > 300] # 5 observations\n",
    "# 3SnPorsch  drop\n",
    "#raw_data.ScreenPorch[raw_data.ScreenPorch > 350]  # 6 observations\n",
    "# poolarea   drop\n",
    "#raw_data.MiscVal[raw_data.MiscVal > 2100]  # 346,705,1230,1457\n",
    "# MoSold    ok\n",
    "# YrSold    ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check distribution and detect outliers\n",
    "for i in raw_data.select_dtypes('int64').drop('Id',axis=1):\n",
    "    sns.distplot(raw_data[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "outliers = []\n",
    "drop_int_feat = []\n",
    "outliers.extend(raw_data.LotArea[raw_data.LotArea > 35000].index.tolist()) \n",
    "outliers.extend(raw_data.OverallQual[raw_data.OverallQual < 2].index.tolist()) \n",
    "outliers.extend(raw_data.OverallCond[raw_data.OverallCond < 2].index.tolist())  \n",
    "outliers.extend(raw_data.BsmtFinSF1[raw_data.BsmtFinSF1 > 2500].index.tolist()) \n",
    "outliers.extend(raw_data.LowQualFinSF[raw_data.LowQualFinSF > 500].index.tolist()) \n",
    "outliers.extend(raw_data.BsmtFullBath[raw_data.BsmtFullBath > 2].index.tolist())\n",
    "outliers.extend(raw_data.FullBath[raw_data.FullBath < 1].index.tolist()) \n",
    "outliers.extend(raw_data.BedroomAbvGr[raw_data.BedroomAbvGr > 6].index.tolist())  \n",
    "outliers.extend(raw_data.KitchenAbvGr[raw_data.KitchenAbvGr > 2].index.tolist()) \n",
    "outliers.extend(raw_data.WoodDeckSF[raw_data.WoodDeckSF > 600].index.tolist()) \n",
    "outliers.extend(raw_data.OpenPorchSF[raw_data.OpenPorchSF > 400].index.tolist()) \n",
    "outliers.extend(raw_data.EnclosedPorch[raw_data.EnclosedPorch > 300].index.tolist()) \n",
    "outliers.extend(raw_data.ScreenPorch[raw_data.ScreenPorch > 350].index.tolist())  \n",
    "outliers.extend(raw_data.MiscVal[raw_data.MiscVal > 2100].index.tolist()) \n",
    "\n",
    "drop_int_feat.append('BsmtHalfBath')\n",
    "drop_int_feat.append('BsmtFinSF2')\n",
    "drop_int_feat.append('3SsnPorch')\n",
    "drop_int_feat.append('PoolArea')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2. Dealing with Missing, Outlier values of Float DataTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.select_dtypes('float64').info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only Float datatype features contains missing values\n",
    "sns.heatmap(raw_data.select_dtypes('float64').isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in raw_data.select_dtypes('float64').columns:\n",
    "    sns.distplot(raw_data[i].dropna())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values after removing outliers\n",
    "\n",
    "outlier = raw_data.LotFrontage[raw_data.LotFrontage > 200].index.tolist()\n",
    "outliers.extend(outlier)\n",
    "m = raw_data.LotFrontage.drop(outlier).mean()\n",
    "s = raw_data.LotFrontage.drop(outlier).std()\n",
    "randoms = np.random.normal(m , s/1.5 , raw_data.LotFrontage.isna().sum())\n",
    "raw_data.LotFrontage[raw_data.LotFrontage.isna()] = randoms\n",
    "\n",
    "\n",
    "outlier = raw_data.MasVnrArea[raw_data.MasVnrArea > 1100].index.tolist()\n",
    "outliers.extend(outlier)\n",
    "m = raw_data.MasVnrArea.drop(outlier).mean()\n",
    "raw_data.MasVnrArea.fillna(m,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "x = np.random.normal(round(raw_data.GarageYrBlt.mean()),\n",
    "                        round(raw_data.GarageYrBlt.std()/2),\n",
    "                        raw_data.GarageYrBlt.isna().sum())\n",
    "raw_data.GarageYrBlt[raw_data.GarageYrBlt.isna()]  =  list(map(round,x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in raw_data.select_dtypes('float64').columns:\n",
    "    sns.distplot(raw_data[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import Counter\n",
    "# Detect outlier using Interquartile rate\n",
    "\n",
    "def outlierDetect(df, no_of_feature_contains = 3):\n",
    "    '''pass pandas\"s dataframe'''\n",
    "    outlier_indices = []\n",
    "    for col in df:\n",
    "        q1 = np.percentile(df[col],25)\n",
    "        q3 = np.percentile(df[col],75)\n",
    "        # IQR\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - 1.5 * iqr\n",
    "        upper = q3 + 1.5 * iqr\n",
    "        outlier_index = df[ (df[col] < lower) | (df[col] > upper)].index.tolist()\n",
    "        outlier_indices.extend(outlier_index)\n",
    "\n",
    "    counted_outliers = Counter(outlier_indices)    \n",
    "    indexs = [k for k,v in counted_outliers.items() if v > no_of_feature_contains] \n",
    "    return indexs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers.extend(outlierDetect(raw_data[int_features],no_of_feature_contains = 5))\n",
    "\n",
    "# Dropping all outliers \n",
    "raw_data.drop(set(outliers), inplace = True)\n",
    "raw_label.drop(set(outliers),inplace = True)\n",
    "\n",
    "# Droping int features\n",
    "raw_data.drop(drop_int_feat,axis=1,inplace=True)\n",
    "\n",
    "int_features = int_features.append(raw_data.select_dtypes('float64').columns)\n",
    "int_features = int_features.drop(drop_int_feat)\n",
    "int_features = int_features.drop('Id')\n",
    "\n",
    "uint8_features = raw_data.select_dtypes('uint8').columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = raw_data[int_features].corr()\n",
    "plt.figure(figsize=(16,16))\n",
    "sns.heatmap(corr, cbar = True,  square = True, \n",
    "            annot=True, fmt= '.2f',annot_kws={'size': 5},\n",
    "           xticklabels= int_features, yticklabels= int_features, \n",
    "            alpha = 0.7,   cmap= 'coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost              import XGBRegressor\n",
    "from sklearn.svm          import SVR\n",
    "from sklearn.ensemble     import RandomForestRegressor\n",
    "from sklearn.ensemble     import AdaBoostRegressor\n",
    "from sklearn.ensemble     import ExtraTreesRegressor \n",
    "from sklearn.ensemble     import GradientBoostingRegressor\n",
    "from sklearn.neighbors    import KNeighborsRegressor\n",
    "from sklearn.metrics      import r2_score, accuracy_score, mean_squared_error\n",
    "from sklearn.pipeline     import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(raw_data.iloc[:,1:],\n",
    "                                                    raw_label,\n",
    "                                                   test_size=.3,\n",
    "                                                   random_state= 45,\n",
    "                                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "new_x_train = sc.fit_transform(x_train[int_features])\n",
    "new_x_test = sc.transform(x_test[int_features])\n",
    "\n",
    "x_train[int_features] = new_x_train\n",
    "x_test[int_features] = new_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8869171873078638"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBRegressor(tree_method='gpu_hist',objective='reg:squarederror')\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = []\n",
    "n_estimators = 200\n",
    "seed = 42\n",
    "pipelines.append( ( 'SVR' , Pipeline( [('SVC',SVR()) ]) ) ) \n",
    "\n",
    "pipelines.append( ( 'KNN' , Pipeline( [('KNN',KNeighborsRegressor()) ]) ) )\n",
    "\n",
    "pipelines.append( ( 'RF'  , Pipeline( [('RF', RandomForestRegressor(random_state=seed, n_estimators=n_estimators)) ]) ) )\n",
    "\n",
    "pipelines.append( ( 'Ada' , Pipeline( [('Ada',AdaBoostRegressor(random_state=seed    , n_estimators=n_estimators)) ]) ) )\n",
    "\n",
    "pipelines.append( ( 'ET'  , Pipeline( [('ET', ExtraTreesRegressor(random_state=seed  , n_estimators=n_estimators)) ]) ) )\n",
    "\n",
    "pipelines.append( ( 'GB'  , Pipeline( [('GB', GradientBoostingRegressor(random_state=seed)) ]) ) )\n",
    "\n",
    "pipelines.append( ( 'XGB'  , Pipeline( [('XGB', XGBRegressor(random_state=seed)) ]) ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, names  = [], []\n",
    "for name, model in pipelines:\n",
    "    cv_results = cross_val_score(model, x_train, y_train, cv = 5 ) \n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    \n",
    "fig = plt.figure(figsize=(12,8))    \n",
    "fig.suptitle(\"Algorithms comparison\")\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = pd.DataFrame(results,index=names,columns=['CV1','CV2','CV3','CV4','CV5'])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = GradientBoostingRegressor()\n",
    "gbm.fit(x_train,y_train)\n",
    "gbm.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbm = XGBRegressor()\n",
    "xgbm.fit(x_train,y_train)\n",
    "xgbm.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbm.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=3, random_state=7)\n",
    "result = cross_val_score(lr, X, y, cv=kfold, scoring='accuracy')\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "params = {'learning_rate':[0.1,0.08,0.05,0.01,0.001],\n",
    "         'gamma':[0.01,0.1,0.3,0.5,1,1.5,2],\n",
    "         'max_depth':[2,4,7,10],\n",
    "         'colsample_bytree':[0.3,0.6,0.8,1],\n",
    "         \"subsample\": [0.2, 0.4, 0.5, 0.6, 0.7],\n",
    "         \"reg_alpha\": [0, 0.5, 1],\n",
    "         \"reg_lambda\": [1, 1.5, 2, 3, 4.5],\n",
    "         \"min_child_weight\": [1, 3, 5, 7],\n",
    "         \"n_estimators\": [100, 250, 500, 1000]}\n",
    "\n",
    "xgb_rscv = RandomizedSearchCV(xgb_clf, param_distributions = params,\n",
    "                             cv = 7, verbose = 3, random_state = 40, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model_xgb = xgb_rscv.fit(x_train,y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (model_xgb.best_score_, model_xgb.best_params_))\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')\n",
    "\n",
    "print(model_xgb.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8906130403751986"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = {'colsample_bytree': 0.3,  # this I get after random search\n",
    "         'gamma': 1.5,\n",
    "         'learning_rate': 0.01,\n",
    "         'max_depth': 7,\n",
    "         'min_child_weight': 1,\n",
    "         'n_estimators': 1000,\n",
    "         'reg_alpha': 0,\n",
    "         'reg_lambda': 1.5,\n",
    "         'subsample': 0.4}\n",
    "\n",
    "model_xgb = XGBRegressor( tree_method='gpu_hist',objective='reg:squarederror',**best_params)\n",
    "model_xgb.fit(x_train,y_train)\n",
    "model_xgb.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12653935868181856"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_xgb.predict(x_test)\n",
    "np.sqrt(mean_squared_log_error( y_test, y_pred ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
